{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext\n",
    "from torchtext import data\n",
    "from torchtext.data import Field\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import preprocessor as p\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize,wordpunct_tokenize\n",
    "import string\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.set_options(p.OPT.URL, p.OPT.EMOJI, p.OPT.MENTION, p.OPT.RESERVED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords.add(\"'s\")\n",
    "stopwords.add(\"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def text_preprocessing(x):\n",
    "#     x = str(x)\n",
    "    \n",
    "#     #cleaning url, @name, emojis, smiley etc\n",
    "#     text = p.clean(x)\n",
    "    \n",
    "#     #punctation removal\n",
    "#     no_punct = [word for word in word_tokenize(text) if word not in string.punctuation]\n",
    "    \n",
    "#     #stopword removal\n",
    "#     no_sw = set(wrd for wrd in no_punct if wrd not in stopwords)\n",
    "    \n",
    "#     return \" \".join(w for w in no_sw if w).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_bigrams(x):\n",
    "    n_grams = set(zip(*[x[i:] for i in range(2)]))\n",
    "    for n_gram in n_grams:\n",
    "        x.append(' '.join(n_gram))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Dataset using TabularDataset from Torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TEXT = Field(sequential=True, preprocessing = data.Pipeline(lambda x : text_preprocessing(x)),\n",
    "#             include_lengths=True)\n",
    "\n",
    "TEXT = Field(tokenize = 'spacy', preprocessing = generate_bigrams, stop_words=stopwords)\n",
    "\n",
    "#include_lengths - converts TEXT into a tuple of two elements, \n",
    "#one element is the numericalised tensor with pads\n",
    "#other element is the actual length of our sentence\n",
    "\n",
    "LABEL = data.LabelField(dtype = torch.float)\n",
    "\n",
    "tweet = data.TabularDataset(path='train_original.csv', format='csv',\n",
    "                            fields={\n",
    "                                'text': ('text', TEXT),\n",
    "                                'target': ('labels', LABEL)\n",
    "                                   }\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT.build_vocab(tweet,max_size = 15000,\n",
    "                 vectors = \"glove.6B.100d\", \n",
    "                 unk_init = torch.Tensor.normal_)\n",
    "\n",
    "LABEL.build_vocab(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TEXT.build_vocab(tweet, max_size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LABEL.build_vocab(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'1': 3271, '0': 4342})"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LABEL.vocab.freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TEXT.vocab.freqs.pop('') # remove empty string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid = tweet.split(split_ratio=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Dataset into Iterator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BucketIterator - \n",
    "\n",
    ">**Shuffles the data in iterator**\n",
    "\n",
    ">**It is recommended that for test data we should use just itertor, since we are evaluating the model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter, val_iter, test_iter = data.BucketIterator.splits((train, valid, None),batch_sizes=(64, 128, 0),\n",
    "                                                            sort_key=lambda x: len(x.text), device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_iter.data()[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(val_iter.data()[99].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 482 ms, sys: 0 ns, total: 482 ms\n",
      "Wall time: 481 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test = data.TabularDataset(path='data/test.csv', format='csv',\n",
    "                            fields={\n",
    "                                'text': ('text', TEXT),\n",
    "                                }\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_iter = data.Iterator(dataset=test, device=device, batch_size=128, sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FastText(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, output_dim, pad_idx):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx)\n",
    "        \n",
    "        self.fc = nn.Linear(embedding_dim, output_dim)\n",
    "        \n",
    "    def forward(self, text):\n",
    "        \n",
    "        #text = [sent len, batch size]\n",
    "        \n",
    "        embedded = self.embedding(text)\n",
    "                \n",
    "        #embedded = [sent len, batch size, emb dim]\n",
    "        \n",
    "        embedded = embedded.permute(1, 0, 2)\n",
    "        \n",
    "        #embedded = [batch size, sent len, emb dim]\n",
    "        \n",
    "        pooled = F.avg_pool2d(embedded, (embedded.shape[1], 1)).squeeze(1) \n",
    "        \n",
    "        #pooled = [batch size, embedding_dim]\n",
    "                \n",
    "        return self.fc(pooled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(TEXT.vocab)\n",
    "EMBEDDING_DIM = 100\n",
    "OUTPUT_DIM = 1\n",
    "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "\n",
    "model = FastText(INPUT_DIM, EMBEDDING_DIM, OUTPUT_DIM, PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 1,500,301 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15002, 100])\n"
     ]
    }
   ],
   "source": [
    "pretrained_embeddings = TEXT.vocab.vectors\n",
    "\n",
    "print(pretrained_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3178,  0.8416, -0.9851,  ...,  0.1316,  1.2739,  0.6057],\n",
       "        [-0.3876, -0.5776,  0.1276,  ..., -0.2854,  0.6830, -2.3014],\n",
       "        [-0.6610, -0.0730,  0.9238,  ..., -0.2256,  0.8148, -0.4405],\n",
       "        ...,\n",
       "        [-1.2171,  0.2461, -0.3521,  ..., -0.4227,  0.0034,  0.9644],\n",
       "        [ 0.0818, -0.6683, -0.4304,  ...,  0.7354, -1.2078,  0.4332],\n",
       "        [ 0.1607, -0.3702,  0.7969,  ...,  0.5758, -0.1443,  0.9382]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embedding.weight.data.copy_(pretrained_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.6610, -0.0730,  0.9238,  ..., -0.2256,  0.8148, -0.4405],\n",
      "        ...,\n",
      "        [-1.2171,  0.2461, -0.3521,  ..., -0.4227,  0.0034,  0.9644],\n",
      "        [ 0.0818, -0.6683, -0.4304,  ...,  0.7354, -1.2078,  0.4332],\n",
      "        [ 0.1607, -0.3702,  0.7969,  ...,  0.5758, -0.1443,  0.9382]])\n"
     ]
    }
   ],
   "source": [
    "UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
    "\n",
    "model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "\n",
    "print(model.embedding.weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.vocab.stoi[TEXT.unk_token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15002, 100])\n"
     ]
    }
   ],
   "source": [
    "print(model.embedding.weight.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded_preds == y).float() #convert into float for division \n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        predictions = model(batch.text).squeeze(1)\n",
    "        \n",
    "        loss = criterion(predictions, batch.labels)\n",
    "        \n",
    "        acc = binary_accuracy(predictions, batch.labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch in iterator:\n",
    "\n",
    "            predictions = model(batch.text).squeeze(1)\n",
    "            \n",
    "            loss = criterion(predictions, batch.labels)\n",
    "            \n",
    "            acc = binary_accuracy(predictions, batch.labels)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.681 | Train Acc: 58.54%\n",
      "\t Val. Loss: 0.646 |  Val. Acc: 62.24%\n",
      "Epoch: 02 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.649 | Train Acc: 64.51%\n",
      "\t Val. Loss: 0.602 |  Val. Acc: 67.86%\n",
      "Epoch: 03 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.610 | Train Acc: 71.39%\n",
      "\t Val. Loss: 0.552 |  Val. Acc: 74.72%\n",
      "Epoch: 04 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.561 | Train Acc: 77.57%\n",
      "\t Val. Loss: 0.516 |  Val. Acc: 77.51%\n",
      "Epoch: 05 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.515 | Train Acc: 80.48%\n",
      "\t Val. Loss: 0.494 |  Val. Acc: 79.24%\n",
      "Epoch: 06 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.474 | Train Acc: 82.96%\n",
      "\t Val. Loss: 0.486 |  Val. Acc: 79.76%\n",
      "Epoch: 07 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.437 | Train Acc: 84.66%\n",
      "\t Val. Loss: 0.484 |  Val. Acc: 79.58%\n",
      "Epoch: 08 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.406 | Train Acc: 85.90%\n",
      "\t Val. Loss: 0.491 |  Val. Acc: 80.76%\n",
      "Epoch: 09 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.382 | Train Acc: 86.74%\n",
      "\t Val. Loss: 0.497 |  Val. Acc: 79.66%\n",
      "Epoch: 10 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.352 | Train Acc: 87.93%\n",
      "\t Val. Loss: 0.512 |  Val. Acc: 80.05%\n",
      "Epoch: 11 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.330 | Train Acc: 88.64%\n",
      "\t Val. Loss: 0.527 |  Val. Acc: 79.79%\n",
      "Epoch: 12 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.310 | Train Acc: 89.47%\n",
      "\t Val. Loss: 0.544 |  Val. Acc: 79.27%\n",
      "Epoch: 13 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.294 | Train Acc: 90.05%\n",
      "\t Val. Loss: 0.566 |  Val. Acc: 79.26%\n",
      "Epoch: 14 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.275 | Train Acc: 90.79%\n",
      "\t Val. Loss: 0.587 |  Val. Acc: 79.00%\n",
      "Epoch: 15 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.261 | Train Acc: 91.25%\n",
      "\t Val. Loss: 0.611 |  Val. Acc: 79.46%\n",
      "Epoch: 16 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.248 | Train Acc: 91.65%\n",
      "\t Val. Loss: 0.635 |  Val. Acc: 78.73%\n",
      "Epoch: 17 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.233 | Train Acc: 92.33%\n",
      "\t Val. Loss: 0.660 |  Val. Acc: 78.79%\n",
      "Epoch: 18 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.219 | Train Acc: 93.02%\n",
      "\t Val. Loss: 0.688 |  Val. Acc: 78.66%\n",
      "Epoch: 19 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.209 | Train Acc: 93.33%\n",
      "\t Val. Loss: 0.715 |  Val. Acc: 78.21%\n",
      "Epoch: 20 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.198 | Train Acc: 93.52%\n",
      "\t Val. Loss: 0.742 |  Val. Acc: 77.70%\n",
      "Epoch: 21 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.190 | Train Acc: 93.79%\n",
      "\t Val. Loss: 0.772 |  Val. Acc: 77.23%\n",
      "Epoch: 22 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.180 | Train Acc: 94.28%\n",
      "\t Val. Loss: 0.799 |  Val. Acc: 77.63%\n",
      "Epoch: 23 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.171 | Train Acc: 94.73%\n",
      "\t Val. Loss: 0.828 |  Val. Acc: 77.30%\n",
      "Epoch: 24 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.163 | Train Acc: 95.25%\n",
      "\t Val. Loss: 0.857 |  Val. Acc: 77.70%\n",
      "Epoch: 25 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.155 | Train Acc: 95.22%\n",
      "\t Val. Loss: 0.888 |  Val. Acc: 77.83%\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 25\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_acc = train(model, train_iter, optimizer, criterion)\n",
    "    valid_loss, valid_acc = evaluate(model, val_iter, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'tut1-model.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_iter:\n",
    "        predictions = model(batch.text).squeeze(1)\n",
    "        preds = predictions.data.cpu().numpy()\n",
    "        #preds = preds.data.numpy()\n",
    "        # the actual outputs of the model are logits, so we need to pass these values to the sigmoid function\n",
    "        preds = 1 / (1 + np.exp(-preds))\n",
    "        test_preds.append(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.where(np.concatenate(test_preds, axis=0) > 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('data/test.csv')\n",
    "test_data[\"target\"] = predictions\n",
    "submission_file = test_data[['id', 'target']]\n",
    "submission_file.to_csv(\"fxt_txt_Submission_file.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
