{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext\n",
    "from torchtext import data\n",
    "from torchtext.data import Field\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import preprocessor as p\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize,wordpunct_tokenize\n",
    "import string\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.set_options(p.OPT.URL, p.OPT.EMOJI, p.OPT.MENTION, p.OPT.RESERVED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords.add(\"'s\")\n",
    "stopwords.add(\"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preprocessing(x):\n",
    "    x = str(x)\n",
    "    \n",
    "    #cleaning url, @name, emojis, smiley etc\n",
    "    text = p.clean(x)\n",
    "    \n",
    "    #punctation removal\n",
    "    no_punct = [word for word in word_tokenize(text) if word not in string.punctuation]\n",
    "    \n",
    "    #stopword removal\n",
    "    no_sw = set(wrd for wrd in no_punct if wrd not in stopwords)\n",
    "    \n",
    "    return \" \".join(w for w in no_sw if w).strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Dataset using TabularDataset from Torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = Field(sequential=True, preprocessing = data.Pipeline(lambda x : text_preprocessing(x)),\n",
    "            include_lengths=True)\n",
    "\n",
    "# TEXT = Field(tokenize = 'spacy',\n",
    "#              include_lengths=True)\n",
    "\n",
    "#include_lengths - converts TEXT into a tuple of two elements, \n",
    "#one element is the numericalised tensor with pads\n",
    "#other element is the actual length of our sentence\n",
    "\n",
    "LABEL = data.LabelField(dtype = torch.float)\n",
    "\n",
    "tweet = data.TabularDataset(path='train_original.csv', format='csv',\n",
    "                            fields={\n",
    "                                'text': ('text', TEXT),\n",
    "                                'target': ('labels', LABEL)\n",
    "                                   }\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT.build_vocab(tweet,max_size = 15000,\n",
    "                 vectors = \"glove.6B.100d\", \n",
    "                 unk_init = torch.Tensor.normal_)\n",
    "\n",
    "LABEL.build_vocab(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TEXT.build_vocab(tweet, max_size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LABEL.build_vocab(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'1': 3271, '0': 4342})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LABEL.vocab.freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38587"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.vocab.freqs.pop('') # remove empty string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid = tweet.split(split_ratio=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Dataset into Iterator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BucketIterator - \n",
    "\n",
    ">**Shuffles the data in iterator**\n",
    "\n",
    ">**It is recommended that for test data we should use just itertor, since we are evaluating the model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter, val_iter, test_iter = data.BucketIterator.splits((train, valid, None),batch_sizes=(64, 128, 0),\n",
    "                                                            sort_key=lambda x: len(x.text), device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_iter.data()[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(val_iter.data()[99].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.92 s, sys: 0 ns, total: 2.92 s\n",
      "Wall time: 2.92 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test = data.TabularDataset(path='data/test.csv', format='csv',\n",
    "                            fields={\n",
    "                                'text': ('text', TEXT),\n",
    "                                }\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_iter = data.Iterator(dataset=test, device=device, batch_size=128, sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, \n",
    "                 bidirectional, dropout, pad_idx):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\n",
    "        \n",
    "        self.rnn = nn.LSTM(embedding_dim, \n",
    "                           hidden_dim, \n",
    "                           num_layers=n_layers, \n",
    "                           bidirectional=bidirectional, \n",
    "                           dropout=dropout)\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, text, text_lengths):\n",
    "        \n",
    "        #text = [sent len, batch size]\n",
    "        \n",
    "        embedded = self.dropout(self.embedding(text))\n",
    "        \n",
    "        #embedded = [sent len, batch size, emb dim]\n",
    "        \n",
    "        #pack sequence\n",
    "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths, enforce_sorted=False)\n",
    "        \n",
    "        packed_output, (hidden, cell) = self.rnn(packed_embedded)\n",
    "        \n",
    "        #unpack sequence\n",
    "        output, output_lengths = nn.utils.rnn.pad_packed_sequence(packed_output)\n",
    "\n",
    "        #output = [sent len, batch size, hid dim * num directions]\n",
    "        #output over padding tokens are zero tensors\n",
    "        \n",
    "        #hidden = [num layers * num directions, batch size, hid dim]\n",
    "        #cell = [num layers * num directions, batch size, hid dim]\n",
    "        \n",
    "        #concat the final forward (hidden[-2,:,:]) and backward (hidden[-1,:,:]) hidden layers\n",
    "        #and apply dropout\n",
    "        \n",
    "        hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n",
    "                \n",
    "        #hidden = [batch size, hid dim * num directions]\n",
    "            \n",
    "        return self.fc(hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(TEXT.vocab)\n",
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 256\n",
    "OUTPUT_DIM = 1\n",
    "N_LAYERS = 3\n",
    "BIDIRECTIONAL = True\n",
    "DROPOUT = 0.5\n",
    "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "\n",
    "model = RNN(INPUT_DIM, \n",
    "            EMBEDDING_DIM, \n",
    "            HIDDEN_DIM, \n",
    "            OUTPUT_DIM, \n",
    "            N_LAYERS, \n",
    "            BIDIRECTIONAL, \n",
    "            DROPOUT, \n",
    "            PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 5,387,817 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15002, 100])\n"
     ]
    }
   ],
   "source": [
    "pretrained_embeddings = TEXT.vocab.vectors\n",
    "\n",
    "print(pretrained_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6093,  1.1288, -0.3286,  ...,  0.4432, -0.9317, -0.3256],\n",
       "        [ 0.4628, -0.9749,  0.4209,  ..., -1.1212,  1.2555,  1.1448],\n",
       "        [ 0.7467,  1.5334, -0.6696,  ...,  0.2919,  0.2122, -0.6511],\n",
       "        ...,\n",
       "        [ 0.2251,  0.5239, -1.4983,  ...,  2.3330, -0.2560, -0.5038],\n",
       "        [-0.8306,  0.0777, -0.0441,  ..., -0.6532,  0.7827, -0.4262],\n",
       "        [ 0.3743, -1.5479, -0.4312,  ..., -0.8107, -0.3086, -0.6888]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embedding.weight.data.copy_(pretrained_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.7467,  1.5334, -0.6696,  ...,  0.2919,  0.2122, -0.6511],\n",
      "        ...,\n",
      "        [ 0.2251,  0.5239, -1.4983,  ...,  2.3330, -0.2560, -0.5038],\n",
      "        [-0.8306,  0.0777, -0.0441,  ..., -0.6532,  0.7827, -0.4262],\n",
      "        [ 0.3743, -1.5479, -0.4312,  ..., -0.8107, -0.3086, -0.6888]])\n"
     ]
    }
   ],
   "source": [
    "UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
    "\n",
    "model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "\n",
    "print(model.embedding.weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.vocab.stoi[TEXT.unk_token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15002, 100])\n"
     ]
    }
   ],
   "source": [
    "print(model.embedding.weight.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded_preds == y).float() #convert into float for division \n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        text, text_lengths = batch.text\n",
    "        \n",
    "        predictions = model(text, text_lengths).squeeze(1)\n",
    "        \n",
    "        loss = criterion(predictions, batch.labels)\n",
    "        \n",
    "        acc = binary_accuracy(predictions, batch.labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch in iterator:\n",
    "\n",
    "            text, text_lengths = batch.text\n",
    "            \n",
    "            predictions = model(text, text_lengths).squeeze(1)\n",
    "            \n",
    "            loss = criterion(predictions, batch.labels)\n",
    "            \n",
    "            acc = binary_accuracy(predictions, batch.labels)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 0m 2s\n",
      "\tTrain Loss: 0.620 | Train Acc: 66.46%\n",
      "\t Val. Loss: 0.552 |  Val. Acc: 72.27%\n",
      "Epoch: 02 | Epoch Time: 0m 2s\n",
      "\tTrain Loss: 0.538 | Train Acc: 73.57%\n",
      "\t Val. Loss: 0.548 |  Val. Acc: 73.04%\n",
      "Epoch: 03 | Epoch Time: 0m 2s\n",
      "\tTrain Loss: 0.497 | Train Acc: 76.78%\n",
      "\t Val. Loss: 0.519 |  Val. Acc: 74.52%\n",
      "Epoch: 04 | Epoch Time: 0m 2s\n",
      "\tTrain Loss: 0.450 | Train Acc: 79.70%\n",
      "\t Val. Loss: 0.495 |  Val. Acc: 75.84%\n",
      "Epoch: 05 | Epoch Time: 0m 2s\n",
      "\tTrain Loss: 0.426 | Train Acc: 81.44%\n",
      "\t Val. Loss: 0.498 |  Val. Acc: 77.01%\n",
      "Epoch: 06 | Epoch Time: 0m 2s\n",
      "\tTrain Loss: 0.392 | Train Acc: 82.51%\n",
      "\t Val. Loss: 0.508 |  Val. Acc: 76.84%\n",
      "Epoch: 07 | Epoch Time: 0m 2s\n",
      "\tTrain Loss: 0.362 | Train Acc: 84.76%\n",
      "\t Val. Loss: 0.513 |  Val. Acc: 76.97%\n",
      "Epoch: 08 | Epoch Time: 0m 2s\n",
      "\tTrain Loss: 0.332 | Train Acc: 85.99%\n",
      "\t Val. Loss: 0.574 |  Val. Acc: 76.90%\n",
      "Epoch: 09 | Epoch Time: 0m 2s\n",
      "\tTrain Loss: 0.316 | Train Acc: 87.15%\n",
      "\t Val. Loss: 0.534 |  Val. Acc: 76.88%\n",
      "Epoch: 10 | Epoch Time: 0m 2s\n",
      "\tTrain Loss: 0.290 | Train Acc: 87.65%\n",
      "\t Val. Loss: 0.554 |  Val. Acc: 77.29%\n",
      "Epoch: 11 | Epoch Time: 0m 2s\n",
      "\tTrain Loss: 0.264 | Train Acc: 88.87%\n",
      "\t Val. Loss: 0.630 |  Val. Acc: 77.95%\n",
      "Epoch: 12 | Epoch Time: 0m 2s\n",
      "\tTrain Loss: 0.252 | Train Acc: 89.59%\n",
      "\t Val. Loss: 0.646 |  Val. Acc: 76.70%\n",
      "Epoch: 13 | Epoch Time: 0m 2s\n",
      "\tTrain Loss: 0.235 | Train Acc: 90.63%\n",
      "\t Val. Loss: 0.631 |  Val. Acc: 77.15%\n",
      "Epoch: 14 | Epoch Time: 0m 2s\n",
      "\tTrain Loss: 0.211 | Train Acc: 91.31%\n",
      "\t Val. Loss: 0.717 |  Val. Acc: 76.19%\n",
      "Epoch: 15 | Epoch Time: 0m 2s\n",
      "\tTrain Loss: 0.206 | Train Acc: 91.42%\n",
      "\t Val. Loss: 0.732 |  Val. Acc: 76.99%\n",
      "Epoch: 16 | Epoch Time: 0m 2s\n",
      "\tTrain Loss: 0.185 | Train Acc: 92.77%\n",
      "\t Val. Loss: 0.710 |  Val. Acc: 76.39%\n",
      "Epoch: 17 | Epoch Time: 0m 2s\n",
      "\tTrain Loss: 0.178 | Train Acc: 92.91%\n",
      "\t Val. Loss: 0.727 |  Val. Acc: 76.78%\n",
      "Epoch: 18 | Epoch Time: 0m 2s\n",
      "\tTrain Loss: 0.164 | Train Acc: 93.82%\n",
      "\t Val. Loss: 0.772 |  Val. Acc: 76.63%\n",
      "Epoch: 19 | Epoch Time: 0m 2s\n",
      "\tTrain Loss: 0.147 | Train Acc: 94.51%\n",
      "\t Val. Loss: 0.856 |  Val. Acc: 76.61%\n",
      "Epoch: 20 | Epoch Time: 0m 2s\n",
      "\tTrain Loss: 0.147 | Train Acc: 94.26%\n",
      "\t Val. Loss: 0.772 |  Val. Acc: 76.68%\n",
      "Epoch: 21 | Epoch Time: 0m 2s\n",
      "\tTrain Loss: 0.126 | Train Acc: 95.26%\n",
      "\t Val. Loss: 0.834 |  Val. Acc: 76.79%\n",
      "Epoch: 22 | Epoch Time: 0m 2s\n",
      "\tTrain Loss: 0.130 | Train Acc: 95.02%\n",
      "\t Val. Loss: 0.844 |  Val. Acc: 77.18%\n",
      "Epoch: 23 | Epoch Time: 0m 2s\n",
      "\tTrain Loss: 0.118 | Train Acc: 95.14%\n",
      "\t Val. Loss: 0.933 |  Val. Acc: 76.52%\n",
      "Epoch: 24 | Epoch Time: 0m 2s\n",
      "\tTrain Loss: 0.111 | Train Acc: 95.59%\n",
      "\t Val. Loss: 0.887 |  Val. Acc: 76.38%\n",
      "Epoch: 25 | Epoch Time: 0m 2s\n",
      "\tTrain Loss: 0.117 | Train Acc: 95.49%\n",
      "\t Val. Loss: 0.891 |  Val. Acc: 76.37%\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 25\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_acc = train(model, train_iter, optimizer, criterion)\n",
    "    valid_loss, valid_acc = evaluate(model, val_iter, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'tut1-model.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_iter:\n",
    "        text, text_lengths = batch.text\n",
    "        predictions = model(text, text_lengths).squeeze(1)\n",
    "        preds = predictions.data.cpu().numpy()\n",
    "        #preds = preds.data.numpy()\n",
    "        # the actual outputs of the model are logits, so we need to pass these values to the sigmoid function\n",
    "        preds = 1 / (1 + np.exp(-preds))\n",
    "        test_preds.append(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.where(np.concatenate(test_preds, axis=0) > 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('data/test.csv')\n",
    "test_data[\"target\"] = predictions\n",
    "submission_file = test_data[['id', 'target']]\n",
    "submission_file.to_csv(\"Submission_file.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
